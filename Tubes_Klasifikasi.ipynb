# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from collections import Counter
from sklearn import preprocessing

#import dataset
dataset = pd.read_csv('air_bnb.csv')
print(dataset)

#Mengecek Data yang Null
print(dataset.isnull().sum())
print(dataset.info())
print('')

idx = []
idx.extend(dataset[dataset['name'].isnull()].index.tolist())
idx.extend(dataset[dataset['host_name'].isnull()].index.tolist())
idx.extend(dataset[dataset['last_review'].isnull()].index.tolist())
idx.extend(dataset[dataset['reviews_per_month'].isnull()].index.tolist())
idx.extend(dataset[dataset['availability_365'] > 365] .index.tolist())
idx.extend(dataset[dataset['minimum_nights'] <= 0] .index.tolist())
idx.extend(dataset[dataset['price'] <= 0] .index.tolist())
idx.extend(dataset[dataset['calculated_host_listings_count'] <= 0] .index.tolist())
idx = list(dict.fromkeys(idx))
len(idx)

#delete null
print("Awal: ", len(dataset))
dataset.drop(idx, inplace = True)
print("Akhir: ", len(dataset))
print(dataset.isnull().sum())
print(dataset.info())

#drop attribute
dataset = dataset.drop(['id', 'name', 'host_id', 'host_name' ,'latitude','longitude'], axis = 1)
dataset
dataset.to_excel('air_bnb.xls', index = False)
print('Done')
# dataset

import seaborn as sns
from numpy import median
ng = dataset.iloc[:,[0]]
print(Counter(ng["neighbourhood_group"]))
sns.set(style="ticks", color_codes=True)
sns.set(rc={'figure.figsize':(28,14)})
ax = sns.countplot(x=ng["neighbourhood_group"], data=ng)
plt.show(ax)

print('')
print(list(dataset.columns))
print(dataset)
print('')
print('')

NewDataset = dataset.copy()
#prediksi Room type
#Dengan neighbourhood_group, price, min_nights
#Kelas adalah Room Type
dataset = NewDataset.copy()
X = dataset.iloc[:, [0, 3, 4, ]].values
y = dataset.iloc[:, 2].values
print(len(X))
# # len(newDS)

# dataset
print(X)
print('')

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder = LabelEncoder()
X[:, 0,] = labelencoder.fit_transform(X[:, 0,])
onehotencoder = OneHotEncoder(categories= 'auto')
X = onehotencoder.fit_transform(X).toarray()
print(X)


# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#Logistic Regression classification algorithm
from sklearn.linear_model import LogisticRegression
logmodel=LogisticRegression()
logmodel.fit(X_train, y_train)
#predict
y_pred = logmodel.predict(X_test)


# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(sum(cm[0] + cm[1] +cm[2]))
print(cm)
print('')

#Hasil 
print('Metode Logistic Regression')
from sklearn.metrics import classification_report
cr = classification_report(y_test,y_pred)
print (cr)
print('')
#end of Logistic Regression


# Decision Tree classification algorithm
from sklearn.tree import DecisionTreeClassifier, plot_tree
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)
# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(sum(cm[0] + cm[1] +cm[2]))
print(cm)
print('')

print('Metode Decision Tree')
from sklearn.metrics import classification_report
cl = classification_report(y_test,y_pred)
print (cl)
#end of decision tree
    









